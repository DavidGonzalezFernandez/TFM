{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lazypredict.Supervised import LazyClassifier\n",
    "from lazypredict.Supervised import LazyRegressor\n",
    "import utils\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.neighbors import NearestCentroid, KNeighborsRegressor\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "import os\n",
    "\n",
    "from utils import HELOC_NAME, ADULT_INCOME_NAME, HIGGS_NAME, COVERTYPE_NAME, CALIFORNIA_HOUSING_NAME, ARBOVIRUSES_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(X_train, X_val, y_train, y_val, models, is_dataset_classification):\n",
    "    if len(models) == 0:\n",
    "        return []\n",
    "    \n",
    "    if is_dataset_classification:\n",
    "        lazy_ = LazyClassifier(\n",
    "            verbose=0,\n",
    "            ignore_warnings=True,\n",
    "            custom_metric=None,\n",
    "            classifiers=models  \n",
    "        )\n",
    "    else:\n",
    "        lazy_ = LazyRegressor(\n",
    "            verbose=0,\n",
    "            ignore_warnings=False,\n",
    "            custom_metric=None,\n",
    "            regressors=models\n",
    "        )\n",
    "    scores, predictions = lazy_.fit(X_train, X_val, y_train, y_val)\n",
    "    print(scores)\n",
    "    model_dictionary = lazy_.provide_models(X_train, X_val, y_train, y_val)\n",
    "    return model_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFIERS = [\n",
    "    GaussianNB,\n",
    "    RandomForestClassifier,\n",
    "    SVC,\n",
    "    NearestCentroid,\n",
    "    LogisticRegression,\n",
    "    DecisionTreeClassifier,\n",
    "]\n",
    "\n",
    "REGRESSORS = [\n",
    "    RandomForestRegressor,\n",
    "    SVR,\n",
    "    KNeighborsRegressor,\n",
    "    LinearRegression,\n",
    "    DecisionTreeRegressor\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_path = utils.get_results_path()\n",
    "base_path = os.path.join(common_path, \"classic_descriptors\")\n",
    "\n",
    "if not os.path.exists(base_path):\n",
    "    os.mkdir(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_EXTENSION = \".joblib\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HELOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = HELOC_NAME\n",
    "\n",
    "dataset_path = os.path.join(base_path, name)\n",
    "if name not in os.listdir(base_path):\n",
    "    os.mkdir(dataset_path)\n",
    "models_to_train = [\n",
    "    c for c in (\n",
    "        CLASSIFIERS if utils.is_dataset_classification(name) else REGRESSORS\n",
    "    ) if c.__name__+FILE_EXTENSION not in os.listdir(dataset_path)\n",
    "]\n",
    "\n",
    "if models_to_train:\n",
    "    X,y = utils.get_X_y(name)\n",
    "    indices_train,indices_val = utils.get_indices_train_eval(name)\n",
    "    X_train, X_val = X[indices_train], X[indices_val]\n",
    "    y_train, y_val = y[indices_train], y[indices_val]\n",
    "    del X\n",
    "    del y\n",
    "\n",
    "    models = train_models(X_train, X_val, y_train, y_val, models_to_train, utils.is_dataset_classification(name))\n",
    "\n",
    "    if models:\n",
    "        for model in models:\n",
    "            model_path = os.path.join(dataset_path, str(model) + FILE_EXTENSION)\n",
    "            dump(model, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adult Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = ADULT_INCOME_NAME\n",
    "\n",
    "dataset_path = os.path.join(base_path, name)\n",
    "if name not in os.listdir(base_path):\n",
    "    os.mkdir(dataset_path)\n",
    "models_to_train = [\n",
    "    c for c in (\n",
    "        CLASSIFIERS if utils.is_dataset_classification(name) else REGRESSORS\n",
    "    ) if c.__name__+FILE_EXTENSION not in os.listdir(dataset_path)\n",
    "]\n",
    "\n",
    "if models_to_train:\n",
    "    X,y = utils.get_X_y(name)\n",
    "    indices_train,indices_val = utils.get_indices_train_eval(name)\n",
    "    X_train, X_val = X[indices_train], X[indices_val]\n",
    "    y_train, y_val = y[indices_train], y[indices_val]\n",
    "    del X\n",
    "    del y\n",
    "\n",
    "    models = train_models(X_train, X_val, y_train, y_val, models_to_train, utils.is_dataset_classification(name))\n",
    "\n",
    "    if models:\n",
    "        for model in models:\n",
    "            model_path = os.path.join(dataset_path, str(model) + FILE_EXTENSION)\n",
    "            dump(model, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# California Housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = CALIFORNIA_HOUSING_NAME\n",
    "\n",
    "dataset_path = os.path.join(base_path, name)\n",
    "if name not in os.listdir(base_path):\n",
    "    os.mkdir(dataset_path)\n",
    "models_to_train = [\n",
    "    c for c in (\n",
    "        CLASSIFIERS if utils.is_dataset_classification(name) else REGRESSORS\n",
    "    ) if c.__name__+FILE_EXTENSION not in os.listdir(dataset_path)\n",
    "]\n",
    "\n",
    "if models_to_train:\n",
    "    X,y = utils.get_X_y(name)\n",
    "    indices_train,indices_val = utils.get_indices_train_eval(name)\n",
    "    X_train, X_val = X[indices_train], X[indices_val]\n",
    "    y_train, y_val = y[indices_train], y[indices_val]\n",
    "    del X\n",
    "    del y\n",
    "\n",
    "    models = train_models(X_train, X_val, y_train, y_val, models_to_train, utils.is_dataset_classification(name))\n",
    "\n",
    "    if models:\n",
    "        for model in models:\n",
    "            model_path = os.path.join(dataset_path, str(model) + FILE_EXTENSION)\n",
    "            dump(model, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arboviruses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = ARBOVIRUSES_NAME\n",
    "\n",
    "dataset_path = os.path.join(base_path, name)\n",
    "if name not in os.listdir(base_path):\n",
    "    os.mkdir(dataset_path)\n",
    "models_to_train = [\n",
    "    c for c in (\n",
    "        CLASSIFIERS if utils.is_dataset_classification(name) else REGRESSORS\n",
    "    ) if c.__name__+FILE_EXTENSION not in os.listdir(dataset_path)\n",
    "]\n",
    "\n",
    "if models_to_train:\n",
    "    X,y = utils.get_X_y(name)\n",
    "    indices_train,indices_val = utils.get_indices_train_eval(name)\n",
    "    X_train, X_val = X[indices_train], X[indices_val]\n",
    "    y_train, y_val = y[indices_train], y[indices_val]\n",
    "    del X\n",
    "    del y\n",
    "\n",
    "    models = train_models(X_train, X_val, y_train, y_val, models_to_train, utils.is_dataset_classification(name))\n",
    "\n",
    "    if models:\n",
    "        for model in models:\n",
    "            model_path = os.path.join(dataset_path, str(model) + FILE_EXTENSION)\n",
    "            dump(model, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covertype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "name = COVERTYPE_NAME\n",
    "\n",
    "dataset_path = os.path.join(base_path, name)\n",
    "if name not in os.listdir(base_path):\n",
    "    os.mkdir(dataset_path)\n",
    "models_to_train = [\n",
    "    c for c in (\n",
    "        CLASSIFIERS if utils.is_dataset_classification(name) else REGRESSORS\n",
    "    ) if c.__name__+FILE_EXTENSION not in os.listdir(dataset_path)\n",
    "]\n",
    "\n",
    "if models_to_train:\n",
    "    X,y = utils.get_X_y(name)\n",
    "    indices_train,indices_val = utils.get_indices_train_eval(name)\n",
    "    X_train, X_val = X[indices_train], X[indices_val]\n",
    "    y_train, y_val = y[indices_train], y[indices_val]\n",
    "    del X\n",
    "    del y\n",
    "\n",
    "    models = train_models(X_train, X_val, y_train, y_val, models_to_train, utils.is_dataset_classification(name))\n",
    "\n",
    "    if models:\n",
    "        for model in models:\n",
    "            model_path = os.path.join(dataset_path, str(model) + FILE_EXTENSION)\n",
    "            dump(model, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HIGGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:28<00:00, 14.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Accuracy  Balanced Accuracy  ROC AUC  F1 Score  Time Taken\n",
      "Model                                                                         \n",
      "LogisticRegression      0.64               0.64     0.64      0.64       16.96\n",
      "NearestCentroid         0.59               0.58     0.58      0.59       11.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "name = HIGGS_NAME\n",
    "\n",
    "CLASSIFIERS = [\n",
    "    GaussianNB,\n",
    "    RandomForestClassifier,\n",
    "    # SVC,\n",
    "    NearestCentroid,\n",
    "    LogisticRegression,\n",
    "    DecisionTreeClassifier,\n",
    "]  \n",
    "\n",
    "dataset_path = os.path.join(base_path, name)\n",
    "if name not in os.listdir(base_path):\n",
    "    os.mkdir(dataset_path)\n",
    "models_to_train = [\n",
    "    c for c in (\n",
    "        CLASSIFIERS if utils.is_dataset_classification(name) else REGRESSORS\n",
    "    ) if c.__name__+FILE_EXTENSION not in os.listdir(dataset_path)\n",
    "]\n",
    "\n",
    "if models_to_train:\n",
    "    X,y = utils.get_X_y(name)\n",
    "    indices_train,indices_val = utils.get_indices_train_eval(name)\n",
    "    X_train, X_val = X[indices_train], X[indices_val]\n",
    "    y_train, y_val = y[indices_train], y[indices_val]\n",
    "    del X\n",
    "    del y\n",
    "\n",
    "    models = train_models(X_train, X_val, y_train, y_val, models_to_train, utils.is_dataset_classification(name))\n",
    "\n",
    "    if models:\n",
    "        for model in models:\n",
    "            model_path = os.path.join(dataset_path, str(model) + FILE_EXTENSION)\n",
    "            dump(model, model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
