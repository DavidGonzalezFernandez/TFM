{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import utils\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import concurrent.futures\n",
    "import joblib\n",
    "from tabulate import tabulate\n",
    "\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, mean_squared_error, precision_score, recall_score, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIC_DESCRIPTORS_EXTENSION = \".joblib\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(model_name_list, predictions_list, targets, is_classification, is_binary_classification, n_classes):\n",
    "    # Checks\n",
    "    if not is_classification:\n",
    "        assert n_classes is None\n",
    "    else:\n",
    "        if is_binary_classification:\n",
    "            assert n_classes == 2\n",
    "        else:\n",
    "            assert n_classes > 2\n",
    "    if is_classification:\n",
    "        headers = [\"model_name\", \"Acc\", \"Balanced_accuracy\", \"Precision\", \"Recall\"]\n",
    "    else:\n",
    "        headers = [\"MSE\", \"RÂ²\"]\n",
    "        \n",
    "    rows = []\n",
    "    for model_name, predictions in zip(model_name_list, predictions_list):\n",
    "        if is_classification:\n",
    "            accuracy = accuracy_score(targets, predictions)\n",
    "            balanced_accuracy = balanced_accuracy_score(targets, predictions)\n",
    "            if is_binary_classification:\n",
    "                precision = precision_score(targets, predictions)\n",
    "                recall = recall_score(targets, predictions)\n",
    "            else:\n",
    "                precision = precision_score(targets, predictions, average='macro')\n",
    "                recall = recall_score(targets, predictions, average='macro')\n",
    "            rows.append([model_name, accuracy, balanced_accuracy, precision, recall])\n",
    "        else:\n",
    "            mse = mean_squared_error(targets, predictions)\n",
    "            r2 = r2_score(targets, predictions)\n",
    "            rows.append([model_name, mse, r2])\n",
    "    formatted_rows = [[row[0]]+[f\"{score:.3f}\" for score in row[1:]] for row in rows]\n",
    "    \n",
    "    print(tabulate(formatted_rows, headers=headers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classic_descriptor_predictions(model_name_list, predictions_list, targets, is_classification, is_binary_classification, n_classes):\n",
    "    evaluate_predictions(model_name_list, predictions_list, targets, is_classification, is_binary_classification, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_partial_load_image(image_method_folder):\n",
    "    def load_image(img_path):\n",
    "        return cv2.imread(\n",
    "            os.path.join(image_method_folder, img_path)\n",
    "        )\n",
    "    \n",
    "    return load_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classic_descriptors(dataset_name):\n",
    "    # Get the path for the models\n",
    "    models_path = utils.get_classicdescriptors_path(dataset_name)\n",
    "\n",
    "    models_to_evaluate = [\n",
    "        m for m in os.listdir(models_path) if m.endswith(CLASSIC_DESCRIPTORS_EXTENSION)\n",
    "    ]\n",
    "\n",
    "    if not models_to_evaluate:\n",
    "        return\n",
    "    \n",
    "    # Load the data\n",
    "    X,y = utils.get_X_y(dataset_name)\n",
    "\n",
    "    # Select the test data\n",
    "    indices = utils.get_indices_test(dataset_name)\n",
    "    X_test, y_test = X[indices], y[indices]\n",
    "    del X\n",
    "    del y\n",
    "\n",
    "    is_classification = utils.is_dataset_classification(dataset_name)\n",
    "    is_binary_classification = utils.is_dataset_binary_classification(dataset_name)\n",
    "    n_classes = utils.get_number_of_classes(dataset_name) if is_classification else None\n",
    "\n",
    "    model_name_list, predictions_list = [], []\n",
    "\n",
    "    # Iterate over all the models\n",
    "    for model_name in models_to_evaluate:\n",
    "        model = joblib.load(os.path.join(models_path, model_name))\n",
    "        model_name_list.append(model_name)\n",
    "\n",
    "        # Calculate the predictions\n",
    "        predictions_list.append(model.predict(X_test))\n",
    "\n",
    "    # Evaluate the predictions\n",
    "    evaluate_classic_descriptor_predictions(\n",
    "        model_name_list = model_name_list, \n",
    "        predictions_list = predictions_list,\n",
    "        targets = y_test,\n",
    "        is_classification = is_classification,\n",
    "        is_binary_classification = is_binary_classification,\n",
    "        n_classes = n_classes\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cnn_predictions(model_name_list, predictions_list, targets, is_classification, is_binary_classification, n_classes):\n",
    "    predictions_list = [predictions.flatten() for predictions in predictions_list]\n",
    "    if is_classification:\n",
    "        if is_binary_classification:\n",
    "            predictions_list = [(predictions > 0.5).astype(int) for predictions in predictions_list]\n",
    "        else:\n",
    "            print(predictions_list[0].shape, targets.shape)\n",
    "            raise NotImplementedError()\n",
    "    else:\n",
    "        predictions_list = predictions_list\n",
    "    evaluate_predictions(model_name_list, predictions_list, targets, is_classification, is_binary_classification, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cnn_models(dataset_name):\n",
    "    model_name_list, predictions_list = [], []\n",
    "\n",
    "    # Get path to models\n",
    "    model_paths = utils.get_cnnmodels_path(dataset_name)\n",
    "\n",
    "    all_model_names = [f for f in os.listdir(model_paths)]\n",
    "    if not all_model_names:\n",
    "        return\n",
    "    \n",
    "    # Get X and y indices\n",
    "    X,y = utils.get_X_y(dataset_name)\n",
    "    indices_test = utils.get_indices_test(dataset_name)\n",
    "    y_test = y[indices_test]\n",
    "    del X,y\n",
    "\n",
    "    for image_method in utils.ALL_IMAGE_METHODS:\n",
    "        # List all the models\n",
    "        model_names = [f for f in all_model_names if f.startswith(image_method)]\n",
    "\n",
    "        # Get path to images\n",
    "        images_path = utils.get_images_path_for_dataset(dataset_name, image_method)\n",
    "\n",
    "        is_classification = utils.is_dataset_classification(dataset_name)\n",
    "        is_binary_classification = utils.is_dataset_binary_classification(dataset_name)\n",
    "        n_classes = utils.get_number_of_classes(dataset_name) if is_classification else None\n",
    "\n",
    "        # Load the images\n",
    "        csv_name = next(f for f in os.listdir(images_path) if f.endswith(\".csv\"))\n",
    "        csv_file = os.path.join(images_path, csv_name)\n",
    "        images_paths = pd.read_csv(csv_file)[\"images\"].to_numpy()[indices_test]\n",
    "        func_load_image = get_partial_load_image(images_path)\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            X_test_img = np.array(list(executor.map(func_load_image, images_paths)))\n",
    "\n",
    "        # Iterate over the methods\n",
    "        for model_name in sorted(model_names):\n",
    "            # Load the model\n",
    "            model_path = os.path.join(model_paths, model_name)\n",
    "            model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "            # Get the predictions\n",
    "            predictions = model.predict(X_test_img, verbose=0)\n",
    "\n",
    "            model_name_list.append(model_name)\n",
    "            predictions_list.append(predictions)\n",
    "\n",
    "    # Calculate the metrics\n",
    "    evaluate_cnn_predictions(\n",
    "        model_name_list = model_name_list, \n",
    "        predictions_list = predictions_list,\n",
    "        targets = y_test,\n",
    "        is_classification=is_classification,\n",
    "        is_binary_classification=is_binary_classification,\n",
    "        n_classes=n_classes\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cnn_mlp_models(dataset_name):\n",
    "    model_name_list, predictions_list = [], []\n",
    "\n",
    "    # Get path to models\n",
    "    model_paths = utils.get_cnnmlp_models_path(dataset_name)\n",
    "\n",
    "    all_model_names = [f for f in os.listdir(model_paths)]\n",
    "    if not all_model_names:\n",
    "        return\n",
    "    \n",
    "    # Get X and y indices\n",
    "    X,y = utils.get_X_y(dataset_name)\n",
    "    indices_test = utils.get_indices_test(dataset_name)\n",
    "    X_test_data = X[indices_test]\n",
    "    y_test = y[indices_test]\n",
    "    del X,y\n",
    "\n",
    "    for image_method in utils.ALL_IMAGE_METHODS:\n",
    "\n",
    "        # List all the models\n",
    "        model_names = [f for f in all_model_names if f.startswith(image_method)]\n",
    "\n",
    "        if not model_names:\n",
    "            continue\n",
    "\n",
    "        # Get path to images\n",
    "        images_path = utils.get_images_path_for_dataset(dataset_name, image_method)\n",
    "\n",
    "        is_classification = utils.is_dataset_classification(dataset_name)\n",
    "        is_binary_classification = utils.is_dataset_binary_classification(dataset_name)\n",
    "        n_classes = utils.get_number_of_classes(dataset_name) if is_classification else None\n",
    "\n",
    "        # Load the images\n",
    "        csv_name = next(f for f in os.listdir(images_path) if f.endswith(\".csv\"))\n",
    "        csv_file = os.path.join(images_path, csv_name)\n",
    "        images_paths = pd.read_csv(csv_file)[\"images\"].to_numpy()[indices_test]\n",
    "        func_load_image = get_partial_load_image(images_path)\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            X_test_img = np.array(list(executor.map(func_load_image, images_paths)))\n",
    "\n",
    "        # Iterate over the methods\n",
    "        for model_name in sorted(model_names):\n",
    "            # Load the model\n",
    "            model_path = os.path.join(model_paths, model_name)\n",
    "            model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "            # Get the predictions\n",
    "            predictions = model.predict([X_test_img, X_test_data], verbose=0)\n",
    "\n",
    "            model_name_list.append(model_name)\n",
    "            predictions_list.append(predictions)\n",
    "\n",
    "    # Calculate the metrics\n",
    "    evaluate_cnn_predictions(\n",
    "        model_name_list = model_name_list, \n",
    "        predictions_list = predictions_list,\n",
    "        targets = y_test,\n",
    "        is_classification=is_classification,\n",
    "        is_binary_classification=is_binary_classification,\n",
    "        n_classes=n_classes\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cnn_ml_models(dataset_name):\n",
    "    model_name_list, predictions_list = [], []\n",
    "\n",
    "    # Get path to models\n",
    "    model_paths = utils.get_cnn_classicdescriptors_path(dataset_name)\n",
    "\n",
    "    all_model_names = [f for f in os.listdir(model_paths)]\n",
    "    if not all_model_names:\n",
    "        return\n",
    "    \n",
    "    # Get X and y indices\n",
    "    X,y = utils.get_X_y(dataset_name)\n",
    "    indices_test = utils.get_indices_test(dataset_name)\n",
    "    X_test_data = X[indices_test]\n",
    "    y_test = y[indices_test]\n",
    "    del X,y\n",
    "    \n",
    "    for image_method in utils.ALL_IMAGE_METHODS:\n",
    "        # List all the models\n",
    "        model_names = [f for f in all_model_names if f.startswith(image_method)]\n",
    "\n",
    "        if not model_names:\n",
    "            continue\n",
    "\n",
    "        # Get path to images\n",
    "        images_path = utils.get_images_path_for_dataset(dataset_name, image_method)\n",
    "\n",
    "        is_classification = utils.is_dataset_classification(dataset_name)\n",
    "        is_binary_classification = utils.is_dataset_binary_classification(dataset_name)\n",
    "        n_classes = utils.get_number_of_classes(dataset_name) if is_classification else None\n",
    "\n",
    "        # Load the images\n",
    "        csv_name = next(f for f in os.listdir(images_path) if f.endswith(\".csv\"))\n",
    "        csv_file = os.path.join(images_path, csv_name)\n",
    "        images_paths = pd.read_csv(csv_file)[\"images\"].to_numpy()[indices_test]\n",
    "        func_load_image = get_partial_load_image(images_path)\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            X_test_img = np.array(list(executor.map(func_load_image, images_paths)))\n",
    "\n",
    "        # Iterate over the methods\n",
    "        for model_name in sorted(model_names):\n",
    "            # Load the model\n",
    "            model_path = os.path.join(model_paths, model_name)\n",
    "            model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "            classic_model = joblib.load(\n",
    "                os.path.join(\n",
    "                    utils.get_classicdescriptors_split1_path(dataset_name),\n",
    "                    model_name.split(\"_\")[1].strip()\n",
    "                )\n",
    "            )\n",
    "            X_classic_predictions = classic_model.predict(X_test_data)\n",
    "\n",
    "            # Get the predictions\n",
    "            predictions = model.predict([X_test_img, X_classic_predictions], verbose=0)\n",
    "\n",
    "            model_name_list.append(model_name)\n",
    "            predictions_list.append(predictions)\n",
    "    \n",
    "    # Calculate the metrics\n",
    "    evaluate_cnn_predictions(\n",
    "        model_name_list = model_name_list, \n",
    "        predictions_list = predictions_list,\n",
    "        targets = y_test,\n",
    "        is_classification=is_classification,\n",
    "        is_binary_classification=is_binary_classification,\n",
    "        n_classes=n_classes\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_classic_descriptors(dataset_name=utils.HELOC_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_cnn_models(dataset_name=utils.HELOC_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_cnn_mlp_models(dataset_name=utils.HELOC_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_cnn_ml_models(dataset_name=utils.HELOC_NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
